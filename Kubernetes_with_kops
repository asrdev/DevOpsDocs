Please find the below steps to setup kubernetes with kops:
Reference URL: https://jee-appy.blogspot.com/2017/10/setup-kubernetes-cluster-kops-aws.html

Pre-requisites:
- Ubuntu machines with AWS CLI installed.
  Follow this step to install aws-cli using python-pip:
     apt update
     apt ugrade
     apt install python-pip
     pip --version
     pip install awscli
     pip install --upgrade pip
     aws --version
     
     Note: Create a group called kubernetes and add a user which has following access.
           AmazonEC2FullAccess
           AmazonRoute53FullAccess
           AmazonS3FullAccess
           IAMFullAccess
           AmazonVPCFullAccess
           
     aws configure  --> AWS ACCESS_KEY & SECRET_KEY is required to configure(Go to IAM User and download the keys)
     
- curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl
  chmod +x ./kubectl
  sudo mv ./kubectl /usr/local/bin/kubectl
  
- curl -LO https://github.com/kubernetes/kops/releases/download/$(curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d '"' -f 4)/kops-linux-amd64
  chmod +x kops-linux-amd64
  sudo mv kops-linux-amd64 /usr/local/bin/kops
  
Create Route53 domain for the cluster
  -Below can be performed only after adding a user into a group under IAM with AWDAdministerAccess && AmazonRoute53FullAccess.
  -kubernetes uses DNS for discovery inside the cluster so that you can reach out kubernetes API server from clients.
    create a hosted zone on Route53, say, manic.com The API server endpoint will then be api.manic.com
    Goto Route53 hosted zone--> Create Hosted Zone--> Fill Domain Name as "manic.com" with description and Type as "Private" & VPC ID/Region as default vpcID with us-east-2
    
 Create S3 Bucket to store all kubernetes state transaction store, so that k8s can fetch the details and do deployment accordingly.
   - From ubuntu machine where aws-cli installed.
      - aws s3 mb s3://clusters.manic.com
      -Navigate to S3 bucket and check the creation of bucket.
      
      Expose environment variable:
      $ export KOPS_STATE_STORE=s3://clusters.manic.com
      $ echo $KOPS_STATE_STORE
 
 Note: Below kops command may throw error if ssh public keys are not already generated. find below steps.
   -In a command prompt, run:  ssh-keygen -t rsa -C "your_email@example.com"
    Enter for para phrase and keep them default. You are done.
    
   - In a command prompt, run:  kops create secret --name k8s-clusters.manic.com --state s3://clusters.manic.com sshpublickey admin -i ~/.ssh/id_rsa.pub
     Note: If the above command throw error, pls check the cluster name and proceed with further command below.
     
 Create Kubernetes Cluster
   -Now weâ€™re ready to create a cluster. You can reuse existing VPC (kops will create a new subnet in this VPC) by providing the vpc-id option:
   $ kops create cluster --cloud=aws --zones=us-east-2b --name=useast2.manic.com --dns-zone=manic.com --dns private
   
   
    
    
To actually create cluster run:
  $ kops update cluster useast2.manic.com --yes 
 
  Try after master and slave nodes are initialized.
  $ kops validate cluster
  
--->This will do all the required stuff of creating the VPC, subnets, autoscaling-groups, nodes etc. which you can observe in the output. If you want to review what all things going to happen when this command would be run then run the above command without --yes option. Without --yes option, it will print the action it is going to perform without actually doing it.
--You can then edit the cluster settings with one of these commands: 
   -List clusters with: kops get cluster
   -Edit this cluster with: kops edit cluster useast2.k8s.manic.com
   -Edit your node instance group: kops edit ig --name=useast2.k8s.manic.com nodes
   -Edit your master instance group: kops edit ig --name=useast2.k8s.manic.com master-us-east-2c
    
Then wait, it takes quite some time for the instances to boot and the DNS entries to be added in the zone. Once everything is up you should be able to get the kubernetes nodes:

   $ kubectl get nodes
   NAME                           STATUS AGE  VERSION
    ip-172-20-33-144.ec2.internal Ready  4m   v1.9
    ip-172-20-39-78.ec2.internal  Ready  1m   v1.9
    ip-172-20-45-174.ec2.internal Ready  2m   v1.9
    
Deploying the Dashboard UI
The Dashboard UI is not deployed by default. To deploy it, run the following command:

kubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml   
    
Then you can use the kubctl proxy to access the UI from your machine:
$ kubectl proxy --port=8080 &   
      
Deploying Nginx Container
To test our new Kubernetes cluster, we could deploy a simple service made up of some nginx containers:
Create an nginx deployment:

$ kubectl run sample-nginx --image=nginx --replicas=2 --port=80
   Result: deployment.apps/sample-nginx created
   
$ kubectl get pods

NAME                       READY     STATUS    RESTARTS   AGE
sample-nginx-379829228-xb9y3   1/1       Running   0          10s
sample-nginx-379829228-yhd25   1/1       Running   0          10s

$ kubectl get deployments

NAME       DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
sample-nginx   2         2         2            2           29s

Expose the deployment as service. This will create an ELB in front of those 2 containers and allow us to publicly access them:
 
$ kubectl expose deployment sample-nginx --port=80 --type=LoadBalancer

$ kubectl get services -o wide

NAME         CLUSTER-IP      EXTERNAL-IP                                                              PORT(S)   AGE       SELECTOR
kubernetes   100.64.0.1      <none>                                                                   443/TCP   25m       <none>
sample-nginx     100.70.129.69   adca6650a60e611e7a66612ae64874d4-175711331.us-east-1.elb.amazonaws.com/   80/TCP    19m       run=sample-nginx
 
There is an ELB running on http://adca6650a60e611e7a66612ae64874d4-175711331.us-east-1.elb.amazonaws.com with our nginx containers behind it:   

You can also view the UI by accessing master node. Hit master node's IP/Domain in browser, it will ask for credentials. 

Run command kubectl config view to see the credentials.
    
    
    
    
    
  

